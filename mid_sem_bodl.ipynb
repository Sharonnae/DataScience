{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mid-semester assignment Part 1 - Basics of deep learning\n",
        "Hello dear students,<br> this is the template notebook. Please upload it into your drive and open as Google Colab nootebook\".\n",
        "\n",
        "---\n",
        "<br>\n",
        "\n",
        "### Name and ID:\n",
        "Student 1: Rotem Cohen, 208544338\n",
        "<br>\n",
        "Student 2: Sharon Nae, 205945538"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "XDDbguyGU8Fs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fashion MNIST\n",
        "Fashion MNIST dataset contains 70,000 grayscale images in 10 categories. The images show individual articles of clothing at low resolution (28 by 28 pixels), as seen here:\n",
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\"\n",
        "         alt=\"Fashion MNIST sprite\"  width=\"600\">\n",
        "  </td></tr>\n",
        "  \n",
        "</table>\n",
        "\n"
      ],
      "metadata": {
        "id": "JLkWLC8f3HZI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the dataset returns four NumPy arrays:\n",
        "\n",
        "* The `train_images` and `train_labels` arrays are the *training set*—the data the model uses to learn.\n",
        "* The model is tested against the *test set*, the `test_images`, and `test_labels` arrays.\n",
        "\n",
        "The images are 28x28 NumPy arrays, with pixel values ranging between 0 and 255. The *labels* are an array of integers, ranging from 0 to 9. These correspond to the *class* of clothing the image represents:\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>Label</th>\n",
        "    <th>Class</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>0</td>\n",
        "    <td>T-shirt/top</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>1</td>\n",
        "    <td>Trouser</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>2</td>\n",
        "    <td>Pullover</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>3</td>\n",
        "    <td>Dress</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>4</td>\n",
        "    <td>Coat</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>5</td>\n",
        "    <td>Sandal</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>6</td>\n",
        "    <td>Shirt</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>7</td>\n",
        "    <td>Sneaker</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>8</td>\n",
        "    <td>Bag</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>9</td>\n",
        "    <td>Ankle boot</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "<br>\n",
        "\n",
        "# Goodluck!"
      ],
      "metadata": {
        "id": "WiRxNFCn3Vxd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Neural Network in plain NumPy"
      ],
      "metadata": {
        "collapsed": false,
        "id": "4K84YZ_QU8Fv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "QReFpU112hLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "tLOHjUiFU8Fv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Dataset"
      ],
      "metadata": {
        "id": "D5MsCpUv2tuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = fetch_openml('Fashion-MNIST', version=1, return_X_y=True, as_frame=False)\n",
        "print(X.shape, y.shape)"
      ],
      "metadata": {
        "id": "nbzv9ZYA2pyW",
        "outputId": "92ccfc52-3479-4527-e10e-f7853d1aadfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(70000, 784) (70000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPBGGKtSoVpU"
      },
      "source": [
        "## Data preprocessing (10%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZfq8otp-wXY"
      },
      "source": [
        "### Feature scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MZtZIzzDIKe",
        "outputId": "67ea5fed-45a1-4d9a-e0d1-aead0879c9ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "examples = y.shape[0]\n",
        "y1 = y.reshape(1, examples)\n",
        "X1 = X / 255\n",
        "X1 = X1.T\n",
        "print(X1.shape)\n",
        "print(y1.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(784, 70000)\n",
            "(1, 70000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6K01j7A_Z4W"
      },
      "source": [
        "### Select two classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OuPZ0o8DNWq"
      },
      "source": [
        "#TODO: select two classes (for example 2-Pullover and 4-Coat)\n",
        "\n",
        "#Lets filter for 1-Trousers and 0-Tshirt/tops\n",
        "class1 = '0'\n",
        "class2 = '1'\n",
        "filtered_X1_data = []\n",
        "y_filtered_labels = []\n",
        "\n",
        "filtered_classes = y1[0][(y1[0]== class1) | (y1[0]== class2)]\n",
        "\n",
        "y_filtered_labels = np.array(filtered_classes.reshape(1, filtered_classes.shape[0]))\n",
        "\n",
        "for (key, class_label) in enumerate(y1[0]): \n",
        "  if class_label == class1 or class_label == class2:\n",
        "    filtered_X1_data.append(X1[:,key])\n",
        "\n",
        "X1_filtered_np = np.array(filtered_X1_data).T"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cn5UPcIQH2jS"
      },
      "source": [
        "### Split the data into Train set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBUI2DZmhd0y"
      },
      "source": [
        "# TODO: Split the data into Train set and Test set (The use of libraries other than Numpy is strictly prohibited)\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "X = X1_filtered_np\n",
        "Y = y_filtered_labels\n",
        "\n",
        "# Use shuffle to mix the training data\n",
        "X, y = shuffle(X1_filtered_np.T, y_filtered_labels.T)\n",
        "\n",
        "filtered_X_training = 12600\n",
        "filtered_Y_training = 12600\n",
        "\n",
        "X_train, X_test = X[:filtered_X_training,:].T, X[filtered_X_training:,:].T\n",
        "Y_train, Y_test = y[:filtered_Y_training,:].T, y[filtered_Y_training:,:].T"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg7D7fwGH9Yv"
      },
      "source": [
        "### Test yourself"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkLl0PSyDR9S",
        "outputId": "a320d5e1-9414-4909-9e0e-582558892a91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "# Test yourself (Check that the classes you have selected are actually displayed)\n",
        "%matplotlib inline\n",
        "from numpy import random\n",
        "\n",
        "i = random.randint(100)\n",
        "plt.imshow(X_train[:,i].reshape(28,28), cmap = matplotlib.cm.binary)\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "Y_train.T[i,0]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q81OW5M7oCWZ"
      },
      "source": [
        "## Activation functions (10%)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxruxXBsDmP-"
      },
      "source": [
        "#TODO: Sigmoid activation function\n",
        "def sigmoid(z):\n",
        "    return (1 / (1 + np.exp( -z )))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBIAUcVboOG9"
      },
      "source": [
        "## Loss function (20%)\n",
        "BCE Loss function captures the intuition that the neural network should pay a high penalty(Loss→∞) when the estimated probability, with respect to the training example’s label, is completely wrong. On the other hand, the Loss should equal zero(Loss=0) when the estimated probability, with respect to the training example’s label, is correct. Simply put, the BCE Loss should equal zero in only two instances:<br>\n",
        "* if the example is positively labeled(y=1) the neural network model should be completely sure that the example belongs to the positive class i.e p̂=1.\n",
        "* if the example is negatively labeled(y=0) the neural network model should be completely sure that the example does not belong to the positive class i.e p̂=0.\n",
        "\n",
        "<b> When we work with a computer, there are very high values or very low values that it cannot handle and that could cause the system to crash. <br>In order to overcome the case where the function returns values that strive for infinity you will need to understand which range of values causes the logarithm to return inf \\ -inf and handle this within the function. </b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0i2o9_KDUdQ"
      },
      "source": [
        "#TODO: Binary cross entropy\n",
        "def log_loss(y_hat, y): \n",
        "    es = 1e-15\n",
        "    predicted = np.clip(y_hat, es, 1 - es)\n",
        "    result = (-((y * np.log10(predicted)) + (1-y) * np.log10(1 - predicted)).mean()).mean()\n",
        "\n",
        "    return result"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WY9DQPrJmvHZ"
      },
      "source": [
        "## NN Hyper Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGCU_QYRnJap"
      },
      "source": [
        "input_layer = X_train.shape[0] # 28X28 = 784\n",
        "hidden_layer = X_train.shape[0]\n",
        "learning_rate = 0.35\n",
        "epochs = 10"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6SdHpc2m3vV"
      },
      "source": [
        "## Weight and Bias Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVRoMGxTnLZI"
      },
      "source": [
        "W1 = np.random.randn(hidden_layer, input_layer) \n",
        "b1 = np.zeros((hidden_layer, 1))\n",
        "W2 = np.random.randn(1, hidden_layer) \n",
        "b2 = np.zeros((1, 1))"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fp-IaWECn6Hu"
      },
      "source": [
        "## Training (30%)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tdlcCGLDo7F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3739aa2-3992-4282-e772-0ae5c86a8206"
      },
      "source": [
        "X = X_train\n",
        "Y = Y_train   \n",
        "loss_list = []\n",
        "epoch_list = []\n",
        "numOfTraining = X_train.shape[1] #Write the number of examples in your train set\n",
        "\n",
        "\n",
        "def f_forward(x, w1, w2):\n",
        "    # hidden\n",
        "    z1 = x.dot(w1)# input from layer 1\n",
        "    a1 = sigmoid(z1)# output of layer 2\n",
        "     \n",
        "    # Output layer\n",
        "    z2 = a1.dot(w2.T)# input of out layer\n",
        "    a2 = sigmoid(z2)# output of out layer\n",
        "    return(a2)\n",
        "\n",
        "\n",
        "\n",
        "# Back propagation of error\n",
        "def back_prop(x, y, b1, b2, w1, w2, alpha):\n",
        "     \n",
        "    # hidden layer\n",
        "    z1 = x.dot(w1) \n",
        "    a1 = sigmoid(z1) \n",
        "     \n",
        "    # Output layer\n",
        "    z2 = a1.dot(w2.T) # input of out layer\n",
        "    a2 = sigmoid(z2)# output of out layer\n",
        "\n",
        "    # error in output layer\n",
        "    d2 =(a2-np.array(float(y),))\n",
        "    d1 = np.multiply((w2.T.dot((d2.transpose()))).transpose(),\n",
        "                                   (np.multiply(a1, 1-a1)))\n",
        "    # Gradient for w1 and w2\n",
        "    w1_adj = x.transpose().dot(d1)\n",
        "    w2_adj = a1.reshape(-1,1).dot(d2)\n",
        "\n",
        "    # Updating parameters\n",
        "    w1 = w1 - (alpha * (w1_adj))\n",
        "    w2 = w2 - (alpha * (w2_adj))\n",
        "     \n",
        "    return(w1, w2)\n",
        "\n",
        "\n",
        "def training(X, Y, b1, b2, W1, W2, learning_rate):\n",
        "  for i in range(epochs):\n",
        "    epoch_list.append(i)\n",
        "    for j in range(1,numOfTraining):\n",
        "\n",
        "      out = f_forward(X[:,j], W1, W2)\n",
        "      W1, W2 = back_prop(X[:,j], Y[0][j], b1, b2, W1, W2, learning_rate)\n",
        "    \n",
        "    avg_loss = log_loss(out, float(Y[0][j]))\n",
        "    loss_list.append(avg_loss)\n",
        "    print(f\"Average Loss: {avg_loss}\")\n",
        "\n",
        "training(X, Y, b1, b2, W1, W2, learning_rate)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Loss: 0.3010289568048147\n",
            "Average Loss: 0.3010299956639812\n",
            "Average Loss: 0.3010299956639812\n",
            "Average Loss: 0.3010299956639812\n",
            "Average Loss: 0.3010299956639812\n",
            "Average Loss: 0.3010299956639812\n",
            "Average Loss: 0.3010299956639812\n",
            "Average Loss: 0.3010299956639812\n",
            "Average Loss: 0.3010299956639812\n",
            "Average Loss: 0.3010299956639812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdgCk97534-B"
      },
      "source": [
        "### Loss Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFo9NN5Q31X8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(epoch_list, loss_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results"
      ],
      "metadata": {
        "id": "5HV5g7j92Xfn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raBFclM5ploH"
      },
      "source": [
        "### Test your performance (30%)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flfh-luxDs7Z"
      },
      "source": [
        "#TODO: Forward batch of examples\n",
        "X = X_test\n",
        "Y = Y_test\n",
        "\n",
        "Out=[]\n",
        "for j in range(X_test.shape[0]):\n",
        "\n",
        "  Out.append(f_forward(X_test[:,j], W1, W2))\n",
        "  predictions = np.zeros((1,Y.shape[1]))\n",
        "  labels = np.zeros((1,Y.shape[1]))\n",
        "\n",
        "  for i in range(len(Out[0])):\n",
        "    if(Out[0][i]>0.5):\n",
        "        predictions.tolist().append(1)\n",
        "        labels.tolist().append(Y_test[0][i])\n",
        "\n",
        "\n",
        "# Print the confusion matrix In order to test your performance\n",
        "print(confusion_matrix(predictions[0], labels[0]))\n",
        "\n",
        "#Print Accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(predictions[0], labels[0])*100,\"%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize the results"
      ],
      "metadata": {
        "id": "7FtZr0EQBlcm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAj_5W2wVUrI"
      },
      "source": [
        "#TODO: SHOW VISUALLY RESULTS ON 10 TEST EXAMPLES\n",
        "%matplotlib inline\n",
        "from numpy import random\n",
        "\n",
        "j = random.randint(100, 200)\n",
        "\n",
        "\n",
        "for i in range(j,j+11,1):\n",
        "  print(i)\n",
        "  plt.imshow(X_test[:,i].reshape(28,28), cmap = matplotlib.cm.binary)\n",
        "  plt.axis(\"off\")\n",
        "  plt.show()\n",
        "  Y_test.T[i,0]\n",
        "\n",
        "  Z1 = np.matmul(W1,X_test[:,i]) +b1\n",
        "  A1 =sigmoid(Z1)\n",
        "  Z2 = np.matmul(W2,X_test[:,i]) +b2\n",
        "  A2 = sigmoid(Z2)\n",
        "  Yout = Y.T[i,0] \n",
        "  print(\"Real=\", Y_test.T[i,0], \"Predicted=\",A2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l2QZIQcUvToK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}